import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Load the dataset
df = pd.read_csv('/mnt/data/train_and_test2.csv')

# Display basic info
print("Initial Data Overview:")
print(df.info())
print("\nMissing Values:")
print(df.isnull().sum())

# Handle missing values (example: fill numerical with mean, categorical with mode)
for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = df[col].fillna(df[col].mode()[0])
    else:
        df[col] = df[col].fillna(df[col].mean())

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Create new features (example: if there's a date column)
for col in df.columns:
    if 'date' in col.lower() or 'time' in col.lower():
        df[col] = pd.to_datetime(df[col], errors='coerce')
        df[col + '_year'] = df[col].dt.year
        df[col + '_month'] = df[col].dt.month
        df[col + '_day'] = df[col].dt.day
        df[col + '_weekday'] = df[col].dt.weekday
        df.drop(col, axis=1, inplace=True)  # drop original datetime

# Feature scaling (standardizing numerical features)
scaler = StandardScaler()
numerical_cols = df.select_dtypes(include='number').columns
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

# Final feature-engineered DataFrame
print("\nFeature-engineered DataFrame:")
print(df.head())
